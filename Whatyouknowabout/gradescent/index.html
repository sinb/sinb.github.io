<!DOCTYPE HTML>
<html>
<head>
<meta name="baidu-site-verification" content="xdZ6LobkoN" />
  <meta charset="utf-8">
  
  <title>梯度下降找方程参数? | Amnesia&#39;s blog</title>
  <meta name="author" content="Amnesia">
  
  <meta name="description" content="">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="梯度下降找方程参数?"/>
  <meta property="og:site_name" content="Amnesia&#39;s blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/css/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Amnesia&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-54965599-1']);
  
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>



</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Amnesia&#39;s blog</a></h1>
  <h2><a href="/">I&#39;ll be your mirror</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">主页</a></li>
    
      <li><a href="/categories/Life">生活</a></li>
    
      <li><a href="/categories/Whatyouknowabout">科普</a></li>
    
      <li><a href="/categories/Courseranote">Coursera笔记</a></li>
    
      <li><a href="/categories/Artworks">Artworks</a></li>
    
      <li><a href="/links">友链</a></li>
    
      <li><a href="/about">关于</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
    <script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	
  <script src="https://raw.github.com/processing-js/processing-js/v1.4.8/processing.min.js" type="text/javascript"></script> 
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-06-04T06:40:30.000Z"><a href="/Whatyouknowabout/gradescent/">2015-06-04</a></time>
      
      
  
    <h1 class="title">梯度下降找方程参数?</h1>
  

    </header>
    <div class="entry">
      
        <hr>
<a id="more"></a>
<p>机器学习里边,梯度下降用来寻找模型参数.其实它就是在寻找方程的系数,什么方程?能量函数.今天使用形式简单的函数来验证一下,是不是所有形式的方程都能顺利地用梯度下降求解.</p>
<h3 id="线性函数">线性函数</h3><p>这个其实都不用验证,这就是线性回归嘛.不过还是按照从简单到复杂一步步来吧.<br>有这么一个线性函数y=Ax+B,参数A和B就用theta表示了.要用梯度下降拟合参数需要知道两个东西,能量函数和能量函数对于theta的偏导,下面两个函数就做的这个事.<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% linearFunc.m</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">linearFunc</span><span class="params">(x, theta)</span></span></span><br><span class="line"><span class="comment">% y = Ax+B</span></span><br><span class="line"><span class="comment">%%</span></span><br><span class="line">    y = theta(<span class="number">1</span>)*x + theta(<span class="number">2</span>);</span><br><span class="line">    </span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% linearFuncCost.m 返回能量以及梯度</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[J, grad]</span> = <span class="title">linearFuncCost</span><span class="params">(theta, x, y)</span></span></span><br><span class="line">    J = sum( (theta(<span class="number">1</span>)*x + theta(<span class="number">2</span>) - y).^<span class="number">2</span>); <span class="comment">%能量函数,这里为了简单问题没有对m个样本进行归一化,</span></span><br><span class="line">					<span class="comment">%因为我们只是寻找方程参数,并不是线性回归要考虑到样本个数.</span></span><br><span class="line">    grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(theta));</span><br><span class="line">    grad(<span class="number">1</span>) = sum(<span class="number">2</span>*(theta(<span class="number">1</span>)*x + theta(<span class="number">2</span>) - y) .* x); <span class="comment">%两个偏导</span></span><br><span class="line">    grad(<span class="number">2</span>) = sum(<span class="number">2</span>*(theta(<span class="number">1</span>)*x + theta(<span class="number">2</span>) - y));</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>然后呢?我们给定一组x,再用公式来产生正确的y,试试能否通过梯度下降来找到正确的参数theta.<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% LinearTest.m</span></span><br><span class="line"><span class="atom">x</span> = [-<span class="number">10</span>:<span class="number">0.1</span>:<span class="number">10</span>];</span><br><span class="line"><span class="atom">realTheta</span> = [<span class="number">5</span>, <span class="number">2</span>];</span><br><span class="line"><span class="atom">y</span> = <span class="atom">linearFunc</span>(<span class="atom">x</span>, <span class="atom">realTheta</span>);</span><br><span class="line"></span><br><span class="line"><span class="atom">options</span> = <span class="atom">optimset</span>(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">50</span>);</span><br><span class="line"><span class="atom">theta</span> = [<span class="number">1</span>;<span class="number">1</span>];</span><br><span class="line"><span class="atom">theta</span> = <span class="atom">fmincg</span> (@(<span class="atom">t</span>)(<span class="atom">linearFuncCost</span>(<span class="atom">t</span>, <span class="atom">x</span>, <span class="atom">y</span>)), ...</span><br><span class="line">                [<span class="number">1</span>;<span class="number">1</span>], <span class="atom">options</span>);</span><br><span class="line"><span class="atom">fprintf</span>(<span class="atom">theta</span>)</span><br></pre></td></tr></table></figure></p>
<p>这里用到一个优化函数<a href="http://www.mathworks.com/matlabcentral/fileexchange/42770-logistic-regression-with-regularization-used-to-classify-hand-written-digits/content/Logistic%20Regression%20with%20regularisation/fmincg.m" target="_blank" rel="external">fmincg</a>,其实比简单的梯度下降稍微高端一点,用了共厄梯度,是Ng公开课里推荐用的.用fmincg找参数,需要把linearFuncCost当作参数传进去,还有一组初始theta值,随便给个[1;1]就行,还有一个options,比如这里的options规定最多进行50次迭代.当然还有输入x和y,可以看成是样本.结果当然是能找到了,只经过13次迭代.<br><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Iteration     <span class="number">1</span> <span class="string">| Cost: 3.776981e+03</span></span><br><span class="line">Iteration     <span class="number">2</span> <span class="string">| Cost: 9.778718e+02</span></span><br><span class="line">Iteration     <span class="number">3</span> <span class="string">| Cost: 1.037721e+02</span></span><br><span class="line">Iteration     <span class="number">4</span> <span class="string">| Cost: 5.217549e+00</span></span><br><span class="line">Iteration     <span class="number">5</span> <span class="string">| Cost: 1.193253e-02</span></span><br><span class="line">Iteration     <span class="number">6</span> <span class="string">| Cost: 1.155018e-02</span></span><br><span class="line">Iteration     <span class="number">7</span> <span class="string">| Cost: 4.344808e-03</span></span><br><span class="line">Iteration     <span class="number">8</span> <span class="string">| Cost: 2.320043e-03</span></span><br><span class="line">Iteration     <span class="number">9</span> <span class="string">| Cost: 3.970677e-04</span></span><br><span class="line">Iteration    <span class="number">10</span> <span class="string">| Cost: 7.156246e-06</span></span><br><span class="line">Iteration    <span class="number">11</span> <span class="string">| Cost: 5.619422e-08</span></span><br><span class="line">Iteration    <span class="number">12</span> <span class="string">| Cost: 3.901228e-09</span></span><br><span class="line">Iteration    <span class="number">13</span> <span class="string">| Cost: 1.045008e-09</span></span><br><span class="line">Iteration    <span class="number">14</span> <span class="string">| Cost: 5.914386e-27</span></span><br><span class="line">Iteration    <span class="number">15</span> <span class="string">| Cost: 3.352659e-30</span></span><br><span class="line"></span><br><span class="line">    <span class="number">5.0000</span></span><br><span class="line">    <span class="number">2.0000</span></span><br></pre></td></tr></table></figure></p>
<p>给y加点噪声呢?<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = linearFunc(x, realTheta) + <span class="built_in">rand</span>(<span class="number">1</span>, <span class="built_in">length</span>(x))*<span class="number">0.1</span>;</span><br></pre></td></tr></table></figure></p>
<p>再迭代,效果还是很好.<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">4.9993</span><br><span class="line">2.0481</span><br></pre></td></tr></table></figure></p>
<h3 id="复杂一点的函数">复杂一点的函数</h3><p>稍微复杂一点的,什么交叉熵之类的就不验证了,它们是真能找到参数.下面是一个我这几天实际碰到的问题中的一个函数.具体问题不谈,问题的求解转化成了用给定数据拟合这样一个形式的函数的问题.<br>$$ y = \frac{theta(3)}{\sqrt{theta(2) + x}} - \frac{theta(4)}{\sqrt{theta(1) + x}}$$形式略复杂,不过能量函数和偏导还是能写出来的.这个函数由于有4个参数,所以有4个偏导.<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">% f_x.m</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">f_x</span><span class="params">(x, theta)</span></span><br><span class="line">    <span class="title">y</span> = <span class="title">theta</span><span class="params">(<span class="number">3</span>)</span>./<span class="title">sqrt</span><span class="params">(theta<span class="params">(<span class="number">2</span>)</span>+x)</span> - <span class="title">theta</span><span class="params">(<span class="number">4</span>)</span>./<span class="title">sqrt</span><span class="params">(theta<span class="params">(<span class="number">1</span>)</span>+x)</span></span>;</span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<figure class="highlight scilab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> [<span class="title">J</span>, <span class="title">grad</span>] = <span class="title">f_xcost</span><span class="params">(theta, x, y)</span></span></span><br><span class="line">    J = <span class="built_in">sum</span>((y - theta(<span class="number">3</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">2</span>)+x) + theta(<span class="number">4</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">1</span>)+x)).^<span class="number">2</span>);   </span><br><span class="line">    J_a_grad = <span class="built_in">sum</span>(    <span class="number">2</span>*( y - theta(<span class="number">3</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">2</span>) + x) + theta(<span class="number">4</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">1</span>)+x) ).* (-<span class="number">0.5</span>*theta(<span class="number">4</span>)*(theta(<span class="number">1</span>)+x).^(-<span class="number">1.5</span>))    );</span><br><span class="line">    J_b_grad = <span class="built_in">sum</span>(    <span class="number">2</span>*( y - theta(<span class="number">3</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">2</span>) + x) + theta(<span class="number">4</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">1</span>)+x) ).* (<span class="number">0.5</span>*theta(<span class="number">3</span>)*(theta(<span class="number">2</span>)+x).^(-<span class="number">1.5</span>))    );    </span><br><span class="line"></span><br><span class="line">    J_c_grad = <span class="built_in">sum</span>(    <span class="number">2</span>*( y - theta(<span class="number">3</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">2</span>) + x) + theta(<span class="number">4</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">1</span>)+x) ).* ( -<span class="number">1.</span>/<span class="built_in">sqrt</span>(theta(<span class="number">2</span>)+x) )    );</span><br><span class="line">    J_d_grad = <span class="built_in">sum</span>(    <span class="number">2</span>*( y - theta(<span class="number">3</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">2</span>) + x) + theta(<span class="number">4</span>)./<span class="built_in">sqrt</span>(theta(<span class="number">1</span>)+x) ).* ( <span class="number">1.</span>/<span class="built_in">sqrt</span>(theta(<span class="number">1</span>)+x) )    );</span><br><span class="line"></span><br><span class="line">    grad = <span class="matrix">[J_a_grad; J_b_grad;J_c_grad; J_d_grad]</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>再试试.<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">% f_xTest.m</span><br><span class="line"><span class="constant">x</span> = (5:0.1:9);</span><br><span class="line"><span class="constant">realTheta</span> = [2.4;2.9;0.8;0.2];</span><br><span class="line"><span class="constant">y</span> = f_x(x, realTheta);</span><br><span class="line"><span class="constant">initTheta</span> = [1;1;    1;1];</span><br><span class="line"><span class="constant">options</span> = optimset('GradObj', 'on', 'MaxIter', 4000);</span><br><span class="line"><span class="constant">estimateTheta</span> = fmincg (@(t)(f_xcost(t, x, y)), ...</span><br><span class="line">                initTheta, options)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Iteration  <span class="number">3699</span> <span class="string">| Cost: 2.437550e-16</span></span><br><span class="line">estimateTheta =</span><br><span class="line"></span><br><span class="line">    <span class="number">2.5463</span></span><br><span class="line">    <span class="number">2.8467</span></span><br><span class="line">    <span class="number">1.0387</span></span><br><span class="line">    <span class="number">0.4387</span></span><br></pre></td></tr></table></figure>
<p>经过了3699次迭代收敛,但是估计出来的参数却和实际参数偏差很大.只能解释为遇到了局部最小值,掉坑里了.<br>改进的想法是,一次用梯度下降更新4个参数可能有点过快了,尝试一次更新3个参数,留一个不更新.这样每次估计出3个新参和一个不变的参数,用这4个来进行第二次更新,依然更新其中3个,不过不是第一次那3个了.这样经过4次就能更新全了.</p>
<h3 id="结果">结果</h3><p>使用部分更新的办法有时能正确的找到参数,有时也不行,不知道为什么,希望了解数值优化的同学帮帮忙啊.</p>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/Whatyouknowabout/">Whatyouknowabout</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/梯度下降/">梯度下降</a>
  </div>

        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
<!-- Duoshuo Comment BEGIN -->
	<div class="ds-thread"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"sinb"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- Duoshuo Comment END -->
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜尋">
    <input type="hidden" name="q" value="site:sinb.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">分類</h3>
  <ul class="entry">
  
    <li><a href="/categories/Artworks/">Artworks</a><small>8</small></li>
  
    <li><a href="/categories/Courseranote/">Courseranote</a><small>5</small></li>
  
    <li><a href="/categories/Life/">Life</a><small>7</small></li>
  
    <li><a href="/categories/Whatyouknowabout/">Whatyouknowabout</a><small>21</small></li>
  
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">標籤</h3>
  <ul class="entry">
  
    <li><a href="/tags/8bit/">8bit</a><small>1</small></li>
  
    <li><a href="/tags/Algorithms/">Algorithms</a><small>4</small></li>
  
    <li><a href="/tags/CNN/">CNN</a><small>2</small></li>
  
    <li><a href="/tags/CS-Foundation/">CS Foundation</a><small>4</small></li>
  
    <li><a href="/tags/Convolution/">Convolution</a><small>1</small></li>
  
    <li><a href="/tags/Cosine/">Cosine</a><small>1</small></li>
  
    <li><a href="/tags/Coursera/">Coursera</a><small>4</small></li>
  
    <li><a href="/tags/DBN/">DBN</a><small>1</small></li>
  
    <li><a href="/tags/DCT/">DCT</a><small>1</small></li>
  
    <li><a href="/tags/DFT/">DFT</a><small>1</small></li>
  
    <li><a href="/tags/Deep-Learning/">Deep Learning</a><small>2</small></li>
  
    <li><a href="/tags/Dictionary-Learning/">Dictionary Learning</a><small>1</small></li>
  
    <li><a href="/tags/FC/">FC</a><small>2</small></li>
  
    <li><a href="/tags/HMM/">HMM</a><small>1</small></li>
  
    <li><a href="/tags/Image-Restoration/">Image Restoration</a><small>1</small></li>
  
    <li><a href="/tags/Imagenet/">Imagenet</a><small>1</small></li>
  
    <li><a href="/tags/MATLAB/">MATLAB</a><small>1</small></li>
  
    <li><a href="/tags/MNIST/">MNIST</a><small>1</small></li>
  
    <li><a href="/tags/NES/">NES</a><small>2</small></li>
  
    <li><a href="/tags/PCA/">PCA</a><small>2</small></li>
  
    <li><a href="/tags/Paper/">Paper</a><small>3</small></li>
  
    <li><a href="/tags/Processing/">Processing</a><small>5</small></li>
  
    <li><a href="/tags/Sparse-Representation/">Sparse Representation</a><small>1</small></li>
  
    <li><a href="/tags/Theano/">Theano</a><small>1</small></li>
  
    <li><a href="/tags/UFLDL/">UFLDL</a><small>7</small></li>
  
    <li><a href="/tags/Viterbi/">Viterbi</a><small>1</small></li>
  
    <li><a href="/tags/WeekEnd/">WeekEnd</a><small>1</small></li>
  
    <li><a href="/tags/fft/">fft</a><small>1</small></li>
  
    <li><a href="/tags/优先队列/">优先队列</a><small>0</small></li>
  
    <li><a href="/tags/分词/">分词</a><small>1</small></li>
  
    <li><a href="/tags/吉他/">吉他</a><small>1</small></li>
  
    <li><a href="/tags/喝酒/">喝酒</a><small>1</small></li>
  
    <li><a href="/tags/堆排序/">堆排序</a><small>0</small></li>
  
    <li><a href="/tags/排序/">排序</a><small>2</small></li>
  
    <li><a href="/tags/最小二乘/">最小二乘</a><small>1</small></li>
  
    <li><a href="/tags/最近/">最近</a><small>1</small></li>
  
    <li><a href="/tags/树/">树</a><small>1</small></li>
  
    <li><a href="/tags/梯度下降/">梯度下降</a><small>1</small></li>
  
    <li><a href="/tags/演出/">演出</a><small>1</small></li>
  
    <li><a href="/tags/爬虫/">爬虫</a><small>1</small></li>
  
    <li><a href="/tags/电影/">电影</a><small>2</small></li>
  
    <li><a href="/tags/超级玛丽/">超级玛丽</a><small>2</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2015 Amnesia
  
</div>
<div class="clearfix"></div></footer>
  <script src="http://ajax.useso.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>




</body>
</html>